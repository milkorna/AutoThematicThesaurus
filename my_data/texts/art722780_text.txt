Meta анонсировала LLaMA (Large Language Model Meta AI), свою модель NLP с миллиардами параметров и обученную на 20 языках.
Недавно её слили на торренты и товарищи смогли запустить сетку локально на обычном домашнем компьютере, на обычном CPU.
Для этого пришлось ужать модель из 32 битной в 4 битную, уменьшив вес модели с 13 до 4 ГБ.
Попробуем запустить самую маленькую модель LLaMA 7B у себя на домашнем компьютере на середнячке AMD Ryzen 5.
Немного покурив инструкцию https://github.com/ggerganov/llama.cpp по квантинизации модели и компиляции исходников получаем саму модель размером 3.92 ГБ и исполняемый файл llama.exe для запуска под Windows 10 x64.
Создайте папку на диске C:\llama.
Закиньте туда файлы из скачанных архивов model_7b.zip и llama.zip.
Запускаем cmd.exe и входим в нашу папку C:\llama.
Вставляем этот текст в cmd.exe llama.exe -m "C:/llama/model_7b.bin" -t 4 -n 64 --repeat_penalty 1.0 -p "What is the largest country in Europe?:".
Нажимаем Enter.
Скорость генерации примерно по 5 слов в секунду.
Вот некоторые параметры для командной строки:
-p текст запроса, например "What is the largest country in Europe?:".
-n количество отдаваемых токенов.
-t количество потоков CPU который будут задействованы.
И помните правильно поставленный вопрос — это уже половина ответа.
Странно, уже столько времени прошло, а на Хабре до сих пор не упомянули про Alpaca.
