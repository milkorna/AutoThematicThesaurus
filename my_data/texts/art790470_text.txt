Введение.
Салют! Уже ни для кого не секрет, что GigaChat активно развивается, и обновление моделей не заставляет себя долго ждать. Рады сообщить вам, что новые версии GigaChat Lite и GigaChat Pro получили мощный апгрейд и стали еще более креативными, умными и точными в исполнении инструкций, а также получили более высокую оценку, чем ChatGPT (gpt-3.5-turbo-0613) на бенчмарке MMLU . На сегодняшний день GigaChat используют уже более 2,5 миллионов человек.
В новом обновлении GigaChat Lite получил расширение максимального контекста до 32768 токенов (GigaChat Lite+), а GigaChat Pro — до 8192 токенов. Вместе с контекстом мы улучшили качество ответов, превзойдя ChatGPT на русском SBS и английском MMLU, а также сделали апдейт датасетов по экономике, медицине и праву, добавили экспертные и редакторские данные, а также прокачали функции (улучшили работу запросов).
Узнать, как попробовать самую сильную версию GigaChat бесплатно, можно в конце статьи.
Метрики.
Подробности о методике подсчета SBS и других метрик мы раскрывали в предыдущей статье.
SBS (Side-By-Side).
Результаты SBS (52%) GigaChat Pro [25.01.2024] vs ChatGPT [gpt-3.5-turbo-0613] (48%).
Результаты SBS (52%) GigaChat Pro [25.01.2024] vs GigaChat Pro [previous] (48%).
Автоматические метрики после alignment.
При замере MMLU/en 5-shot in system prompt GigaChat Pro побеждает OpenAI ChatGPT.
Две колонки с MMLU отличаются форматом, в котором задания подавались в контекст сети для генерации. Это было сделано, чтобы проверить стабильность результатов. Умение одинаково хорошо давать ответы при разных формулировках — это очень полезное свойство, которое упрощает prompt engineering (разработку затравок). GigaChat — единственная модель, для которой результаты в разных форматах почти не отличаются.
Качество на MMLU/en для GigaChat Pro повысилось на 10,7%, а для GigaChat Lite+ — на 13,0% в абсолютных значениях.
* Состав датасетов был изменен, поэтому метрики отличаются от предыдущей статьи.
** Метрики из GPT-4 Technical Report ( ссылка ).
Воспроизведение замеров.
Воспроизвести замеры можно с помощью кода в репозитории api-mmlu-eval . Приглашаем всех разработчиков моделей поделиться результатами для своих API.
Расширенный контекст.
GigaChat использует внутри себя Rotary Positional Embeddings, поэтому для расширения контекста мы использовали метод NTK-Aware Scaled RoPE, который позволяет взять большее число токенов и интерполировать для них кодировку позиции, основываясь на старой кодировке для более коротких строк.
Для того, чтобы использовать NTK-Aware Scaled RoPE , ****необходимо в уже работающей сети заменить основание в экспоненте, а после продолжить pretrain.
Результаты после расширения говорят о том, что новые модели хорошо работают с расширенным контекстом.
Чтобы проверить работы с новым расширенным контекстом, мы использовали тест PassKey Retrieval.
Доля успешных извлечений ключа:
Как мы видим, GigaChat Lite+ и GigaChat Pro прекрасно справляются с задачей, утилизируя весь свой контекст.
Как попробовать GigaChat.
Одним из самых доступных способов получить доступ к GigaСhat является веб-интерфейс , а также боты в Telegram и VK . Он доступен всем пользователям и позволяет получать ответы от модели в режиме реального времени. Все, что необходимо — стабильный доступ в интернет. Если же вам необходим более гибкий доступ, приглашаем попробовать Gigachat API , который позволяет интегрировать возможности модели в свои приложения и сервисы, а также настраивать параметры в соответствии с конкретными потребностями.
В настоящее время пользователи могут получить Freemium-доступ к GigaChat , в котором доступно 950 тыс. токенов для GigaChat Lite и 50 тыс. токенов для GigaChat Pro.  Freemium предоставляет доступ к базовым возможностям модели. Подробнее про различие в моделях рассказываем в табличке ниже:
Благодарности.
В завершение хотим поблагодарить коллег, которые регулярно принимают участие в улучшении наших моделей и не перестают удивлять своей вовлеченностью и энтузиазмом. Вы лучшая команда!
Заходите в наш Telegram-канал Salute AI , где мы делимся наработками в области машинного обучения, и в чат Salute AI Community , где можно пообщаться с нами лично.
Авторы: Григорий Лелейтнер ( @RunFMe ), Порхун Сергей, Михаил Колесов ( @m1shail ), Лурье Евгений ( @eugenelourie ), Головин Дмитрий ( @GolovinDS ).
