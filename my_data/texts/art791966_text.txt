На сегодняшний день созданы разные большие языковые модели (LLM), которые показывают превосходные результаты, но для раскрытия их полного потенциала необходимо дообучение для точного решения конкретных задач. Традиционный метод файнтюнинга, при котором настраиваются все параметры предварительно обученной модели, становится непрактичным и вычислительно дорогостоящим при работе с современными моделями LLM.
PEFT(Parameter-Efficient Fine-Tuning) представляет собой эффективный подход, позволяющий не терять производительность при тонкой настройке модели, снижая при этом требования к памяти и вычислительным мощностям.
В этой статье мы рассмотрим общую концепцию PEFT, его преимущества и основные методы.
Что такое PEFT?
PEFT - это метод файнтюнинга, который позволяет улучшить результаты предварительно обученных языковых моделей при выполнении определенных задач. Его идея заключается в том, чтобы обучить небольшое подмножество параметров предварительно обученной модели LLM, оставляя большую часть замороженными.
Преимущества PEFT.
Ускорение времени обучения: PEFT позволяет сократить количество времени, затраченное на обучение, благодаря файнтюнингу небольшого количества параметров, а не всей модели.
Снижение затрат на вычисления и хранение: PEFT выполняет тонкую настройку только небольшого подмножества параметров, что значительно уменьшает затраты на вычисления и хранение и снижает требования к оборудованию.
Меньший риск переобучения: Благодаря замораживанию большей части параметров предварительно обученной модели мы можем избежать переобучения на новых данных.
Преодоление катастрофического забывания: С помощью PEFT модель может адаптироваться к новым задачам, сохраняя ранее полученные знания благодаря заморозке большинства параметров.
Удобство развертывания: Контрольные точки, созданные при PEFT, компактнее, чем при традиционной тонкой настройке, что делает их развертывание и перенос на другие устройства более простым, поскольку они требуют меньше места для хранения и могут загружаться быстрее.
Давайте рассмотрим каждый из них поподробнее.
LoRA.
Метод LoRA (Low-Rank Adaptation) был разработан в 2021 году и представлен в данной статье . Его создатели были вдохновлены данной научной работой , в которой авторы отмечают, что, хотя LLM имеют миллионы или даже миллиарды параметров, они имеют низкую "внутреннюю размерность" (intrinsic dimension) при адаптации к новой задаче. Проще говоря, большинство параметров являются избыточными. Из чего можно сделать вывод, что матрицы можно представить пространством меньшей размерности, сохраняя при этом большую часть важной информации.
Создатели LoRA предположили, что изменение весов при файнтюнинге модели имеет низкий "внутренний ранг" (intrinsic rank). Идея данного метода заключается в том, что для предварительно обученной матрицы весов мы представляем её обновление двумя меньшими матрицами, полученными путем низкоранговой аппроксимации. Эти матрицы мы тренируем при обучении, а исходную матрицу весов замораживаем. Затем для получения окончательного результата мы объединяем исходные и обученные веса.
Одним из важнейших параметров является параметр "r" (ранг). Он определяет размер матриц низкого ранга. При правильном выборе ранга данный метод может показать впечатляющие результаты.
Дополнительная информация по методу LoRA:
https://medium.com/@gitlostmurali/understanding-lora-and-qlora-the-powerhouses-of-efficient-finetuning-in-large-language-models-7ac1adf6c0cf.
https://habr.com/ru/articles/757086/.
https://www.unite.ai/lora-qlora-and-qa-lora-efficient-adaptability-in-large-language-models-through-low-rank-matrix-factorization/.
Prefix tuning.
Перед знакомством со следующими тремя методами, хотелось бы ввести термин "аддитивный метод". Под ним подразумевается, что параметры предобученной модели дополняются новыми, и обучение происходит именно на них, тем временем исходные данные заморожены. Данный тип методов PEFT лучше всего изучен и включает в себя большую часть разработанных методов.
На просторах интернета по данной теме можно встретить термин "continuous (virtual) token". Он обозначает эмбеддинги, которые вставляются в промт модели. Они не имеют конкретного соответствия в словаре токенов и являются свободными параметрами, которые можно обучать.
Prefix tuning является аддитивным методом, который оборачивает исходные входные данные в дополнительный контекст для конкретной задачи, однако мы не сами задаем его, а находим с помощью обучения модели.
Суть данного метода заключается в том, что мы добавляем последовательность обучающих векторов (continuous task-specific vectors), называемым префиксом, к каждому блоку трансформера и обучаем только её, не трогая остальные данные.
В оригинальной статье создатели данного метода, исходя из результатов эксперимента на основе GPT-2, сделали вывод, что, обучая только 0,1% параметров, Prefix tuning показывает производительность, сравнимую с дообучением, при котором настраиваются все параметры модели, и превосходит его при файнтюнинге с малым объемом данных.
Дополнительная информация по методу Prefix tuning:
https://magazine.sebastianraschka.com/p/understanding-parameter-efficient.
https://medium.com/@musicalchemist/prefix-tuning-lightweight-adaptation-of-large-language-models-for-customized-natural-language-a8a93165c132.
Prompt tuning.
Prompt tuning - это аддитивный метод, который является упрощенной версией Prefix tuning.
Давайте рассмотрим два типа промтов:
Hard prompts: Такой тип промта можно рассматривать, как некий шаблон. Он создается вручную людьми и является статичным.
Soft prompts: Данный вид cоздается в процессе использования метода Prompt tuning. Мы объединяем входные векторные представления предобученной модели с обучаемым тензором, который затем оптимизируем с помощью обратного распространения ошибки.
В статье "The Power of Scale for Parameter-Efficient Prompt Tuning" авторы показывают, что этот метод является конкурентоспособным, так как разрыв между его производительностью и производительностью при традиционном методе файнтюнинга исчезает при увеличении размера модели.
Дополнительная информация по методу Prompt tuning:
https://cobusgreyling.medium.com/prompt-tuning-hard-prompts-soft-prompts-49740de6c64c.
https://research.ibm.com/blog/what-is-ai-prompt-tuning.
Adapters.
Adapters также является аддитивным методом. Он похож на метод Prefix tuning, только в этом случае мы добавляем не префикс, а адаптеры. Авторы данного метода ( статья ) предложили следующую структуру:
Внутри адаптера исходные d-мерные признаки сначала проецируются в меньшее измерение m, затем применяется нелинейность, а после снова проецируются в d-мерное измерение. Также здесь присутствует skip connection.
В вышеупомянутой статье сравнили производительность при данном методе и при дообучении всех параметров. Результаты таковы: производительность при первом варианте находится в пределах 0,4 % от производительности второго варианта, хотя обучены были лишь 3,6 % от всего количества параметров.
Дополнительная информация по методу Adapters:
https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters#:~:text=The%20idea%20of%20parameter%2Defficient,the%20pretrained%20LLM%20remain%20frozen.
Заключение.
PEFT - это новый подход, который предоставляет нам обширный набор инструментов для эффективного файнтюнинга, помогая избежать множество проблем, таких как катастрофическое забывание, большие затраты ресурсов, риск переобучения и т.д.
Мы познакомились лишь с некоторыми методами PEFT. Для изучения других подходов я рекомендую вам прекрасную статью "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning", в которой подробно рассматриваются 20 различных методов PEFT.
Также можете ознакомиться со следующими статьями по данной теме:
https://www.leewayhertz.com/parameter-efficient-fine-tuning/.
https://lightning.ai/pages/community/article/understanding-llama-adapters/.
https://markovate.com/blog/parameter-efficient-fine-tuning-peft-of-llms-a-practical-guide/.
