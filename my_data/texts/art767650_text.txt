В сентябре 2023 года инженеры из гугла выпустили статью об использовании LLM для различных задач оптимизации. Там нет кода или ссылки на репозиторий, чтобы можно было самому поиграть, поэтому я написал простой оптимизатор с помощью языковой модели (Mistral-7B-Instruct) для задачи линейной регрессии.
Коротко о линейной регрессии.
Линейная регрессия — это модель зависимости одной переменной от другой (или нескольких) с линейной функцией зависимости. Она позволяет предсказывать значение одной переменной на основании другой или нескольких.
Решить задачу линейной регрессии с одной переменной - значит нарисовать линию, которая будет максимально точно соответствовать существующим наблюдениям. Линия - это уравнение, подставив в которое значение X, мы получим предсказанное значение Y:
Чтобы оценить, насколько хорошо наша линия подходит под имеющиеся наблюдения, используют различные методы. Самый известный - метод наименьших квадратов (МНК) . С его помощью мы определяем насколько далеко реальные наблюдения отдалены от нашей линии. Задача - минимизировать эти расстояния.
Функцию, которая рассчитывает расстояния, называют функцией потерь (loss function или cost function). И мы хотим её минимизировать.
Задача линейной регрессии имеет аналитическое решение. Когда с помощью манипуляций с производными мы получаем явную формулу и находим точное решение (правильную линию). Но если переменных и наблюдений слишком много, то аналитическое решение может быть вычислительно-затратным или даже невозможным.
Тогда на помощь приходят итерационные методы. Самый известный - градиентный спуск.
Во время градиентного спуска мы как бы проверяем: если я немного увеличу значение переменной w, то будет ли моя линия лучше подходить под имеющиеся наблюдения? Если да, то я немного увеличиваю w, если нет - уменьшаю. И так двигаюсь до тех пор, пока не окажусь в оптимальном минимуме.
Думаю, что-то похожее будет делать наша языковая модель, когда будет подбирать идеальные коэффициенты на основании только текстовых инструкций.
Больше про линейную регрессию - тут . Про градиентный спуск - тут . Функцию потерь - тут.
Оптимизируем с помощью LLM.
Пайплайн:
Создадим набор данных со значениями y, x;
Случайно инициируем веса (w, b) для нашей линии y_pred = w*x + b;
Передадим модели инструкцию, в которой скажем, какое значение принимает наша функция потерь при заданных w, b. И попросим её изменить w, b таким образом, чтобы уменьшить функцию потерь. (Модель не будет знать, какую функцию мы оптимизируем. Мы будем подавать ей только значения: w, b, loss);
Возьмём предложенные моделью w, b, посчитаем для них loss и снова подадим модели. (Сначала на входе у модели будет всего один пример - случайно инициированные веса, а затем к нему буду добавляться примеры, которые она сама придумала, но не больше 10 штук);
Дождёмся, когда 3 последних значения loss функции станут меньше 1 и примем это за оптимальное решение.
Загружаем модель Mistral-7B-Instruct-v0.1 с Hugging Face:
Создадим набор данных:
Построим график:
Напишем несколько функций для парсинга ответов LLM, расчёта  loss:
Посмотрим loss со случайно инициированными w, b:
Создаём промт:
Запускаем цикл оптимизации:
Посмотрим последние 10 значений loss:
А вот так теперь выглядит наша прямая:
Посмотрим на снижение loos во время оптимизации (ограничил значения 700 единицами, потому что в процессе тренировки было несколько выбросов со значениями больше миллиона).
Интересное наблюдение. Температура ( temperature ), параметр, который отвечает за вариативность ответов модели, играет в нашем случае своеобразную роль шага для градиентного спуска. Чем ниже температура, тем медленнее снижается loss, но в то же время реже встречаются выбросы. И наоборот - чем выше температура, тем более уверенные "шаги" делает модель, быстрее сходится, но и часто отдаёт большие выбросы.
Вот так, например, выглядит снижение loss при temperature =0.5 через каждые 20 итераций:
P. S.
Не стоит рассматривать языковую модель, как реальный инструмент для оптимизации в таких задачах. Для решения задачи линейно регрессии существуют куда более простые, быстрые и менее затратные методы (для запуска Mistral-7B-Instruct в формате bfloat16 требуется видеокарта с памятью как минимум 16Gb).
Но в целом тенденция выглядит немного пугающей. Даже относительно небольшие LLM становятся всё более "умными", а люди находят им всё новые применения. Например, в статье, на которую я ссылался вначале, авторы предлагают метод оптимизации промтов - а это уже реальная заявка на то, чтобы отобрать работу у промт инженеров (ну или по крайней мере внести существенные коррективы в их обучение).
Репозиторий с кодом на GitHub - https://github.com/akocherovskiy/LLM_as_optimizer.
Google Colab, где можно запустить код на бесплатной Т4 - LLM_as_optimizer.
