Что такое Cross-Fold Generation.
RuGPT-3 - AI-модель для русского языка, которая умеет писать тексты. Она может генерировать истории, стихи и новости, которые люди не могут отличить от настоящих. Похожая модель лежит в основе Балаболы от Яндекса. В этой статье мы описываем способ генерации длинных текстов без потери смысла на примере модели ruGPT-3 Large. Мы назвали этот метод Cross-Fold Generation. С ним можно генерировать последовательности более 2000 токенов с сохранением идеи текста.
Описание работы метода и код.
Сейчас при генерации выше, чем 1000 токенов, ruGPT-3 Large сильно отдаляется от первоначальной темы во время генерации, тем самым становится сложно генерировать длинные рассказы и истории.
Способ для генерации, который мы предлагаем, заключается в следующем:
Шаг 1:  Генерируем первые N токенов.
Шаг 2: Генерируем две последовательности с одинаковым количеством токенов, учитывая токены из шага 1.
Шаг 3: Переносим вторую последовательность токенов в начало, а первую ставим на место второй последовательности.
Шаг 4: Повторяем данную последовательность заданное количество раз, перенося первую последовательность вправо.
Мы будем реализовывать этот метод с использованием библиотеки ​ transformers.
Установим пакет transformers версии 4.2.2(не гарантируем работоспособность на других версиях).
Для этой статьи мы заранее дообучили модель на текстах разного жанра, чтобы оценить качество генерации. Сейчас просто загружаем ruGPT-3 и токенайзер для неё.
Реализуем несколько вспомогательных функций.
Функция count_num_of_same_in_list подсчитывает количество одинаковых токенов в списке.
Функция flatten переводит двумерный список в одномерный.
Функция generate генерирует текст с заданными параметрами top_k, top_p и другими.
Функция generate_full_text генерирует полностью текст с выше приведённым алгоритмом.
prompt — строка, с которой будет продолжена генерация.
num_of_seq_tokens — количество последовательностей токенов. Всегда должно быть >= 3.
len_of_seq — количество токенов во всех последовательностях кроме первой.
first_toke len — количество токенов в первой последовательности.
prompt в данном случае это строка вида f'<start>{genre}<title_start>{name}<text_start>', в которой genre —  это жанр текста, а name —  его название.
Количество токенов высчитывается по формуле:
Для примера мы сгенерировали два текста на 2000 токенов с одинаковыми параметрами для генерации и таким промптом '<start>комедия<title_start>Поездка<text_start>'.
Заключение.
Как можно заметить вариант с Cross-Fold Generation допустил меньше повторов и больше имеет связи с началом текста. У ruGPT-3 есть и другие проблемы, но в этой статье мы решили одну из них.
Авторы.
@Арсений Шахматов | @Степан Шабалин | @Максим Герасимов.