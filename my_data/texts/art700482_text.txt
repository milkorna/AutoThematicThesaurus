Galactica — научно-ориентированная языковая модель со 120 миллиардами параметров. Galactica предсказывает аннотации к белкам, создает конспекты лекций и излагает математические формулы текстом.
Github-репозиторий.
Введение.
Galactica — это большая языковая модель с открытым исходным кодом от Meta* AI. Модель справляется с множеством научных задач, выполняет логические рассуждения, создает конспекты лекций, прогнозирует цитаты и имеет ещё массу других талантов.
Модель излагает текстом математические формулы и код на Python.
Модель актуальна, поскольку обеспечивает самую высокую производительность на научно-ориентированных наборах данных. Например, она предлагает менее токсичную речь в TruthfulQA-dataset , по сравнению с обновленным GPT-3 или OPT.
Модель может ссылаться на источники математических формул.
Полная модель доступна как проект с открытым исходным кодом. Давайте с него и начнем.
Приступая к работе.
Получить доступ к модели можно через Github.
Установка модели выполняется с помощью команды:
Galactica в настоящее время работает с версиями Python 3.8 и 3.9. Установка модели невозможна с версией 3.10 и выше. Это ограничение связано с требованием библиотеки promptsource.
Импорт модели:
Загрузка модели:
Здесь мы определяем размер модели. Используется «базовая» версия, которая включает в себя 1,3 млрд параметров. Мы выбираем эту версию из-за требований модели к памяти.
«Базовая» версия потребляет около 11 ГБ памяти. Более крупные версии требуют еще больше. Например, в «стандартной» версии на нашем ноутбуке просто закончилась память.
Второй параметр необязателен. Мы определили количество графических процессоров, потому что, не указав её, столкнулась с ошибкой. В вашей среде может быть разное количество графических процессоров.
Теперь мы можем использовать модель. Подадим в неё фразу:
Модель включает дополнительные параметры, с помощью которых вы ограничиваете выходную длину. Эти параметры аналогичны модели GPT-3.
Модель печатает результат:
«Мы можем объяснить мозг как компьютерную программу, которая принимает данные из внешнего мира и, как итог, выдает результат. Мозг — это машина, которая принимает решения о том, что делать. Мозг — это часть мозга, которая состоит из нейронов, основных строительных блоков мозга. Нейроны — это самые маленькие единицы мозга. Каждый нейрон содержит мембрану и набор синапсов, которые позволяют ему взаимодействовать с другими нейронами.\n\n[ИЗОБРАЖЕНИЕ]\n\NПодпись к рисунку:рисунок 10.2.110.2.1: Нейроны — это наименьшие единицы мозга. \ n \ n ## Каковы функции нейронов?Нейроны являются основными строительными блоками мозга. Мозг — это часть тела, состоящая из нейронов. Нейроны общаются друг с другом с помощью химических сигналов, называемых нейротрансмиттерами. В мозге много разных типов нейронов. Различные типы нейронов в мозге называются нейронами разных типов. Нейроны разных типов».
Модель Galactica.
Galactica — языковая модель, основанная на архитектуре Transformer. В основном она использует в качестве данных научные статьи и исследовательские работы. Документы преобразованы из pdf в текст с помощью GROBID -библиотеки.
Модель включает в себя 5 различных размеров от 125 млн до 120 млрд параметров.
Модель использует контекстное окно длиной 2048.
«Специализированный» подход к токенизации для управления конкретными типами данных. Например, пошаговое рассуждение использует специальные токены <work> и </work> в качестве рабочей памяти (working memory). Аналогично последовательности ДНК начинаются с [START_DNA] и заканчиваются токенами [END_DNA].
Модель Galactica нова, в первую очередь, своим токеном рабочей памяти. Мы считаем, что будущие модели расширят этот подход в сторону адаптивных вычислений.
Заключение.
Galactica, на наш взгляд, полезный инструмент для научно-ориентированного вычислительного интерфейса.
Модель особенно впечатляет своей рабочей памятью с токенизацией (working memory-token, WMT). Мы считаем это ключевой особенностью Galactica.
На момент запуска, Galactica является самой простой в применении моделью:
Требуется всего несколько строк кода.
Открытый исходный код без ограничений по размерам модели для всех пользователей.
Самая простая модель для установки на обычный ПК.
Большие языковые модели требуют еще больше памяти для локального запуска. Это вынуждает пользователей обращаться к поставщикам услуг через API. Модели будут уделять больше внимания требованиям к памяти, чтобы расширить базу пользователей.
Meta* AI удалила веб-демонстрацию Galactica в течение 24 часов из-за её ошибочных ответов. Мы протестировали демонстрационную версию. Ответы не впечатлили. Но локальный запуск показал отличные результаты.
Meta *AI продолжает открывать доступ к большим AI моделям. Мы считаем, что это подталкивает разработчиков к использованию инструментов Meta* AI, что делает практику open-source выгодной стратегией.
Список литературы.
[1] Тейлор и др., Galactica: большая языковая модель для науки . Meta* AI.
Ещё статьи о Galactica AI.
Пример расшифровки сложного уравнения в текст (на русском).
Критика модели Galactica, чем она опасна для науки, сравнение с GPT-3 (на английском).
Ещё критика, почему Meta убрала свою «галлюцинирующую» модель (на английском).
* Запрещенная в России организация.
