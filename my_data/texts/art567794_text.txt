3 - Neural Machine Translation by Jointly Learning to Align and Translate.
В этом третьем посте о моделях sequence-to-sequence с использованием PyTorch и torchText мы будем реализовывать модель из стать Neural Machine Translation by Jointly Learning to Align and Translate. Эта модель демонстрирует лучшую точность из из трёх моделей (~27 по сравнению с ~34 у предыдущей модели).
Как и ранее, если визуальный формат поста вас не удовлетворяет, то ниже ссылки на английскую и русскую версию jupyter notebook:
Исходная версия ( Open jupyter notebook In Colab ).
Русская версия ( Open jupyter notebook In Colab ).
Введение.
Напоминаем общую модель кодера-декодера:
В предыдущей модели наша архитектура была построена таким образом, чтобы уменьшить «сжатие информации» путем явной передачи вектора контекста в декодер на линейный слой на каждом временном шаге, совместно с передачей входного слова, прошедшего через слой эмбеддинга, и со скрытым состоянием.
Несмотря на то, что мы частично уменьшили сжатие информации, наш вектор контекста по-прежнему должен содержать всю информацию об исходном предложении. Модель, реализованная в этом разделе, избегает такого сжатия, позволяя декодеру просматривать все исходное предложение черезегоскрытыесостояния на каждом этапе декодирования! Как это стало возможным? Благодаря вниманию.
Для использования механизма внимания, сначала вычисляем вектор внимания. Каждый элемент вектора внимания находится в диапазоне от 0 до 1, а сумма элементов вектора равна 1. Затем мы вычисляем взвешенную сумму скрытых состояний исходного предложения, чтобы получить взвешенный исходный вектор.
Мы вычисляем новый взвешенный исходный вектор на каждом временном шаге при декодировании, используя его в качестве входных данных для RNN декодера, а также линейного слоя для прогнозирования. Мы объясним, как все это сделать далее.
Подготовка данных.
Снова подготовка аналогична прошлой.
Сначала мы импортируем все необходимые модули.
Установите случайные значения для воспроизводимости.
Загрузите немецкую и английскую модели spaCy.
Для загрузки в Google Colab используем следующие команды (После загрузки обязательно перезапустите colab runtime! Наибыстрейший способ через короткую комаду： Ctrl + M +. ):
Создаем токенизаторы.
Поля остаются теми же, что и раньше.
Загружаем данные.
Создаём словари.
Определяем устройство.
Создаём итераторы.
Создание модели Seq2Seq.
Кодер.
Сначала мы создадим кодер. Как и в предыдущей модели, мы используем только один слой GRU, однако теперь он будет иметь вид двунаправленной RNN. В двунаправленной RNN у нас есть две RNN на каждом уровне. Вперёд-направленная RNN перебирает предложение, прошедшее эмбеддинга, слева направо показанонижезеленымцветом, а назад-направленная RNN перебирает предложение, прошедшее эмбеддинг, справа налево бирюзовый. Все, что нам нужно сделать в коде — установить bidirectional = True, а затем провести предложение через слой эмбеддинга в RNN, как и раньше.
Теперь у нас есть:
Где и.
Как и раньше, мы передаем в RNN только ввод ( embedded ), который сообщает PyTorch о необходимости инициализировать как прямое, так и обратное начальные скрытые состояния ( and, respectively) тензором с нулевыми значениями элементов. Кроме того, мы получаем два вектора контекста: один из прямой RNN после того, как она увидит последнее слово в предложении, а второй из обратной RNN после того, как она зафиксирует первое слово в предложении.
RNN возвращает outputs и hidden.
outputs имеет размер srclen,batchsize,hiddim∗numdirections где первые hid_dim элементов в третьем измерении - это скрытые состояния от верхнего уровня вперёд-направленной RNN, а последнее hid_dim элементов — это скрытые состояния от верхнего уровня назад-направленной RNN. Мы можем думать о третьем измерении как о прямом и обратном скрытых состояниях, связанных вместе друг с другом, т.е., и мы можем обозначить все скрытые состояния кодировщика прямоеиобратноесцеплениевместе как тензорконтекста.
hidden имеет размер nlayers∗numdirections,batchsize,hiddim, где −2,:,: дает скрытое состояние вперёд-направленной RNN верхнего уровня после последнего временного шага т.е.послетого,каконувиделпоследнееслововпредложении и −1,:,: дает верхнему уровню скрытое состояние обратно-направленной RNN после последнего временного шага т.е.послетого,каконувиделпервоеслововпредложении.
Поскольку декодер не является двунаправленным, ему нужен только один вектор контекста для использования в качестве начального скрытого состояния, но в настоящее время у нас есть два вектора контекста ( и, respectively). Мы решаем эту проблему, объединив два вектора контекста вместе, пропустив их через линейный слой и применяя функцию активации.
Замечание : на самом деле здесь есть некоторое отклонение от реализации в статье. В статье авторы передают только первое назад-направленной скрытое состояние RNN через линейный слой, чтобы получить начальное скрытое состояние вектора контекста для декодера. Это кажется бессмысленным, поэтому мы изменили эту часть формирования вектора внимания.
Поскольку мы хотим, чтобы наша модель просматривала все исходное предложение, мы возвращаем outputs, в виде объединённых скрытых состояний вперед и назад для каждого токена в исходном предложении. Мы возвращаем hidden, который действует как начальное скрытое состояние в декодере.
Внимание.
Далее идет слой внимания. Этот слой принимает предыдущее скрытое состояние декодера и все скрытые состояния кодера, собранные в тензор контекста. Слой генерирует вектор внимания длины исходного предложения, каждый элемент которого находится в диапазоне от 0 до 1, а вся сумма элементов вектора равна 1.
Интуитивно понятно, что этот слой берет то, что мы уже декодировали,, и все, что мы закодировали в, для создания вектора, который представляет, каким словам в исходном предложении мы должны уделять большее внимание для правильного предсказать следующее слова декодировщиком.
Сначала мы вычисляем энергию взаимодействия между предыдущим скрытым состоянием декодера и скрытыми состояниями кодера. Поскольку скрытые состояния нашего кодера представляют собой последовательность тензоров, и наше предыдущее скрытое состояние декодера — это одиночный тензор, первое, что мы делаем, это повторяем предыдущее скрытое состояние декодера раз. Затем мы вычисляем энергию взаимодействия между ними, объединив их вместе и пропустив через линейный слой ( attn ) и функцию активации.
Эту величину можно рассматривать как вычисление того, насколько хорошо каждое скрытое состояние кодера «совпадает» с предыдущим скрытым состоянием декодера.
В настоящее время у нас есть dec hid dim, src len тензор для каждого примера в батче. Мы хотим, чтобы он был длины src len для каждого примера в батче, так как внимание должно быть длины исходного предложения. Это достигается путем умножения энергии на 1, dec hid dim -размерный тезор.
Мы можем думать о как о качестве весов взвешенной суммы энергии по всем скрытым состояниям кодировщика. Эти веса говорят нам, насколько мы должны уделять внимание каждому токену в исходной последовательности. Параметры инициализируются случайным образом, но изучаются вместе с остальной частью модели посредством обратного распространения ошибки. Обратите внимание, как v не зависит от времени, и то же время используется для каждого временного шага декодирования. Реализуем как линейный слой без смещения.
Наконец, мы следим за тем, чтобы вектор внимания соответствовал ограничениям, накладываемым на элементы этого вектора при передаче его через слой : все элементы находятся между 0 и 1, и суммирование элементов даёт 1.
Это привлекает внимание к исходному предложению!
Графически это выглядит примерно так, как показано ниже. Так для вычисления самого первого вектора внимания. Зеленые блоки представляют скрытые состояния как от вперёд-направленной, так и назад-направленной RNN, и все вычисления внимания выполняются в розовом блоке.
Декодер.
Далее идет декодер.
Декодер содержит слой внимания, attention, который принимает предыдущее скрытое состояние, все скрытые состояния кодировщика, и возвращает вектор внимания.
Затем мы используем этот вектор внимания для создания взвешенного исходного вектора, который обозначается как weighted, который представляет собой взвешенную сумму скрытых состояний кодировщика, использованный совместно с весами.
Входное слово, прошедшее эмбеддинга, взвешенный исходный вектор, и предыдущее скрытое состояние декодера, все это передаются в декодер RNN, с и и соединяется вместе.
Затем мы передаем, и через линейный слой для совершения предсказания следующего слова в целевом предложении. Это делается путем их объединения.
На изображении ниже показано декодирование первого слова в примере перевода.
Зелёные/бирюзовый блоки показывают RNNs кодера которые выдают H, красный блок показывает вектор контекста,, синий блок показывает RNN декодера, который выводит s_t, фиолетовый блок показывает линейный слой, выводит, а оранжевый блок показывает вычисление взвешенной суммы по от и выходов. Не показан расчет.
Seq2Seq.
Это первая модель, в которой нам не нужно, чтобы RNN кодировщика и RNN декодера имели одинаковые скрытые размеры, однако кодировщик должен быть двунаправленным. Последнее требование можно игнорировать, изменив все размерность входных данных с enc_dim * 2 на enc_dim * 2 if encoder_is_bidirectional else enc_dim.
Эта модель seq2seq инкапсулирует кодер и декодер как и в двух предыдущих моделях. Единственная разница в том, что encoder возвращает как окончательное скрытое состояние который является окончательным скрытым состоянием как от вперёд-направленного, так и от назад-направленного RNN кодировщика, прошедших через линейный уровень для использования в качестве начального скрытого состояния в декодере, а также для каждого скрытого состояния которые представляют собой скрытые состояния на выходе вперёд- и назад-направленные RNNN, накладываемые друг на друга. Нам также необходимо обеспечить, чтобы hidden и encoder_outputs передавались в декодер.
Кратко пройдемся по всем этапам:
тензор outputs создан для хранения всех прогнозов.
исходная последовательность, подается в кодировщик для получения и.
начальное скрытое состояние декодера установлено как вектор context.
мы используем батч токенов <sos> как первый input.
затем декодируем в цикле:вставка входного токена, предыдущее скрытое состояние, и все выходы кодера в декодерполучение прогноза и новое скрытое состояние затем мы решаем, собираемся ли мы применять обучение с принуждением или нет, устанавливая следующий ввод соответствующим образом.
Обучение модели Seq2Seq.
Остальная часть этого урока очень похожа на предыдущий.
Мы инициализируем наши параметры, кодера, декодер и модели seq2seq  поместив его на графический процессор, если он у нас есть.
Мы используем упрощенную версию схемы инициализации весов, использованную в статье. Здесь мы инициализируем все смещения равными нулю и все веса из.
Подсчитаем количество параметров. Получаем прибавку почти 50% по сравнению с количеством параметров из последней модели.
Создаем оптимизатор.
Инициализируем функцию потерь.
Затем мы создаем цикл обучения.
.и цикл оценки, не забывая установить модель на eval режим и отключив обучение с принуждением.
Наконец, определим функцию подсчёта времени.
Затем мы обучаем нашу модель, сохраняя параметры, которые дают нам наименьшие потери при проверке.
Наконец, мы тестируем модель на тестовой выборке, используя эти «лучшие» параметры.
Мы улучшили предыдущую модель, но это произошло за счет удвоения времени обучения.
В следующем разделе мы будем использовать ту же архитектуру, но применим несколько приемов ко всем архитектурам RNN - упакованные дополненные последовательности и маскирование. Мы реализуем код, который позволит нам посмотреть, на какие слова во входных данных RNN обращает внимание при декодировании выходных данных.