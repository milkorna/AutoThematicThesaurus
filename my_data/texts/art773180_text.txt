Галлюцинации — это явление, которое до недавнего времени было привилегией человеческого сознания. Однако, с развитием текстовых генеративных моделей, таких как GigaChat и ChatGPT, возникла возможность наблюдать подобные «иллюзии» и в мире искусственного интеллекта.
Есть случаи, когда галлюцинации генеративной модели вполне уместны. Например, если вы попросите модель сгенерировать детскую сказку, то наличие в ней выдуманных персонажей и событий будет весьма кстати и понравится малышу.
Проблема галлюцинаций генеративных моделей.
Совсем по-другому дело обстоит при вопросах, например, касающихся реальных людей или событий. Тут пользователю хочется получить ответ, в первую очередь, основанный на фактах. Но, к сожалению, современные генеративные модели часто искажают или придумывают несуществующие факты в своих ответах. Причем, самое интересное, что делают они это очень искусно, и по ответу зачастую нельзя понять, придумала модель данное событие или оно действительно имело место быть.
Например, недавно ChatGPT придумала сексуальный скандал, а нарушителем указала реального профессора, сославшись на несуществующую статью в известном журнале. Все это оказалось чистейшей выдумкой, а упомянутый профессор никогда не обвинялся ни в чем подобном.
Откуда берутся галлюцинации генеративных моделей.
Так почему же большие генеративные модели придумывают несуществующие факты? Все дело в том, что в общении человек  основывает свои рассуждения на определенных точках в своей памяти, которые он сам может оценить на достоверность. То есть, если человек упоминает какой-то факт, в котором он не уверен или помнит неточно, он знает об этом и выскажет своему собеседнику неуверенность, используя слова «возможно», «скорее всего» или другие.
Модель же, с другой стороны, не имеет способности оценивать достоверность фактов, которые сохранились в ее весах. Каждое следующее слово генерируется статистически, как наиболее вероятное, при этом, проверять фактологичность получившегося заявления без использования внешних источников знаний ученые пока не научились.
Проблема обрезки знаний.
Другой известной проблемой чат-бот моделей является неосведомленность о последних событиях в мире. В моделях GigaChat и ChatGPT, на текущий момент, знания ограничены примерно серединой — второй половиной 2023-го года. Дата ограничения знаний — это дата, когда был сделан этап предобучения моделей. Обо всем, что произошло после этой даты, модель знать не будет. Как известно, этап предобучения — очень ресурсоемкий и длительный по времени. Он может занимать несколько месяцев, при этом в нем используется большой кластер видеокарт. То есть полностью переобучать большую модель — дорого и долго, поэтому отставание по свежести информации есть у всех больших языковых моделей.
Для пользователей это означает, что модель может выдавать информацию, которая уже устарела. Например, на вопрос о последней модели iPhone, чат-бот может выдать информацию про предыдущую.
Решение с помощью RAG.
Над решением проблем галлюцинаций и отставания во времени по знаниям в генеративных моделях ученые бьются довольно давно. Одним из подходов к их решению, является RAG (Retrieval-Augmented Generation) , то есть генерация, дополненная поисковой выдачей.
В рамках этой статьи мы не будем сильно погружаться в детали реализации исходного подхода. Главное, что авторы предложили вместе с запросом пользователя передавать в модель еще и top-k документов из поисковой выдачи для генерации ответа уже на их основе.
Таким образом, решаются сразу две проблемы: галлюцинация и свежесть знаний. Галлюцинаций удается избежать за счет наличия достоверных фактов в поисковой выдаче, а свежесть знаний достигается за счет свежести индексов, на которых построена поисковая система. Поисковые системы, в свою очередь, научное сообщество уже давно научилось своевременно и эффективно обновлять.
Наша реализация — GigaSearch.
Мы в SberDevices вдохновились этим подходом и реализовали свою версию —GigaSearch.
Работает эта система следующим образом. Опционально, в зависимости от того, к какой системе подключается GigaSearch, запрос пользователя может проходить через классификатор, обученный выявлять фактологические вопросы. В этом случае, мы используем GigaSearch только для них. На остальные, не фактологические запросы, можно отвечать напрямую GigaChat-ом без использования поиска.
Классификатор основан на кодировщике ruElectra, который недавно обучили наши коллеги из RnD. Кстати, эта модель опубликована и доступна публично.
Далее мы подкладываем в промпт GigaChat-а топ-3 документа из нашей поисковой системы. Поиск построен поверх закрытой базы знаний.
Таким образом, GigaChat «видит» не только диалог с пользователем, но и релевантные документы с фактами, которые помогают ответить фактологически точно и учесть последние события в мире.
GigaSearch уже встроен в GigaChat Web, поэтому каждый желающий может «пощупать» систему своими руками, для этого нужно перейти по ссылке https://developers.sber.ru/gigachat/ и зайти в свой аккаунт (при первом входе необходимо зарегистрироваться).
Также GigaSearch скоро появится в ботах в телеграме: @gigachat_bot и в ВК: vk.me/gigachat . Им можно написать напрямую или добавить в ваш чат с друзьями и коллегами.
Как мы уже упоминали, GigaSearch включается при ответе на открытые фактологические вопросы.
Например:
GigaSearch в Салюте.
GigaSearch с недавнего времени также отвечает на фактологические вопросы в нашем ассистенте Салют, поспрашивать его уже можно на всех умных устройствах Sber.
Что дальше?
Качество ответов GigaSearch складывается из качества работы нескольких компонентов:
Качество поисковой системы;
Количество, корректность и актуальность данных в базе знаний;
Умение GigaChat использовать релевантный материал;
Умение GigaChat отвечать из параметрической памяти в случае нерелевантной выдачи.
Мы продолжаем улучшать каждый из этих компонентов, в том числе расширяем базу знаний, используя обратную связь от пользователей. Поэтому ждем пальцы вверх и вниз от вас, для нас это очень важно!
Благодарности.
Хочу сказать большое спасибо коллегам, которые участвовали в этом проекте. Все получилось только благодаря вашему позитивному заряду и нескончаемой энергии!
На связи с вами.
Также приглашаю вас в наш Telegram-канал Salute AI , в котором мы с коллегами начали делиться наработками в области машинного обучения и другими рабочими моментами. А в соответствующем чатике Salute AI Community можно напрямую поспрашивать про всё это и просто пообщаться.
