Задача – «Провести анализ сообщений коммерческого чата на предмет игнорирования вопроса клиента менеджером компании».
На входе: лог чатов с клиентом компании в csv формате:
План решения:
Подготовка данных.
Выбор инструмента для определения похожих сообщений внутри каждого чата.
Анализ полученных результатов.
Подведение итогов.
Подготовка данных.
Применяются следующие инструменты:
Выполнена загрузка CSV файлов в DataFrame. Форматы дат в разных логах отличаются, поэтому они приведены к единому виду. Сортировка выполнена по номерам чатов и датам сообщений, также проводиться сброс/упорядочивание индексов.
>>>.
Размер DF, rows = 144584.
На основании группировки делаем вывод, что основная часть сообщений чата приходиться на клиентов и консультантов компании. Изредка наблюдаются автоматические сообщения системы.
Размер большинства чатов – 25 сообщений.
Проведена обработка текста: нижний регистр, игнорирование сообщений с одним словом, оставляем только русские буквы, пробел и тире. Удалены из сообщений тексты о вложениях документов вида «картинка.jpg».
Заменяем несколько пробелов одним пробелом.
Чистим от частотных/не значимых словосочетаний:
Приводим слова к нормальной форме, удалим из текста частотные слова.
Выбор инструмента для поиска похожих сообщений внутри каждого чата.
Найдем расстояние Левенштейна всех заявок по всем текстам:
В результате тестирования была обнаружена самая производительная библиотека для расчета редакционного расстояния Левенштейна – editdistance.
Расчет затраченного времени в секундах на обработку 29463 сообщений чата представлен ниже. В тесте участвовали import edit_distance, import editdistance, import textdistance, from jellyfish import:
Библиотека editdistance производительнее аналогов от 18 до 31 раза.
Чтобы определить допустимую схожесть текстов используем метрику CURRENT_LEVEN, которая ограничит допустимое значение отношения редакционного расстоянию двух сравниваемых текстов к длине первого текста — editdistance (text1, text2)/ длину текста(text1).
Значение параметра CURRENT_LEVEN подбирается опытным путем. Проведением итерации расчета и добавления стоп-слов. Значение зависит от средней длины сравниваемых текстов и индивидуально для каждого исследования. В моем случае рабочий CURRENT_LEVEN составил 0.25.
Анализ полученных результатов.
Формируется dataframe из расчетных данных:
Разворот сообщений в строки:
Добавляются признаки к датафрейму df_users_rep_msg.
Посмотрим на сообщения, количество которых повторяются более 6 раз в одном чате.
Следует уделить внимание на чаты, в которых присутствуют частотные сообщения от клиентов, как в примере выше, и выяснить причину настойчивости и удовлетворённость клиента сервисом.
Разметим основной дата фрейм.
Получим минимальный и максимальный индекс по каждому совпавшему сообщению.
В примере ниже видно, как обращение перехватил бот/автоматизированная система, клиент не игнорирован.
Проверяем остальные случаи.
Количество обработанных сообщений:
Заключение.
С помощью NLP модели, построенной на измерении редакционного расстояния по Левенштейну, удалось сократить кол-во проверяемых чатов с 5406 ед. до 339 ед. Из них определить высоко-рисковые чаты — 103 ед. Определить и использовать в расчетах высокопроизводительную библиотеку для расчета дистанции редактирования между текстами, позволяющую масштабировать проверку на большие объемы информации.