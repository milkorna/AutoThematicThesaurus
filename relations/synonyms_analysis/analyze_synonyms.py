import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict

# Function to load JSON data
def load_json(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

# Loading data files
deep_pavlov_data = load_json('synonyms_mask_deep_pavlov.json')
rut5_data = load_json('synonyms_rut5_base_paraphraser.json')
sbert_data = load_json('synonyms_sbert.json')
usage_variants_data = load_json('usage_variants.json')

# Dictionary to store all phrase information
all_phrases_info = defaultdict(dict)

# --- Processing DeepPavlov Data ---
for phrase, content in deep_pavlov_data.items():
    all_phrases_info[phrase]["deep_pavlov"] = {
        "oof_prob_class": content.get("oof_prob_class"),
        "is_term_manual": content.get("is_term_manual"),
        "synonyms": content.get("synonyms", [])
    }

# --- Processing RuT5 Data ---
for phrase, content in rut5_data.items():
    all_phrases_info[phrase]["rut5"] = {
        "oof_prob_class": content.get("oof_prob_class"),
        "is_term_manual": content.get("is_term_manual"),
        "top_paraphrases": content.get("top_paraphrases", []),
        "found_in_data": content.get("found_in_data", [])
    }

# --- Processing SBERT Data ---
for phrase, content in sbert_data.items():
    all_phrases_info[phrase]["sbert"] = {
        "oof_prob_class": content.get("oof_prob_class"),
        "is_term_manual": content.get("is_term_manual"),
        "synonyms": content.get("synonyms", [])
    }

# --- Processing Usage Variants Data (list of dictionaries) ---
for item in usage_variants_data:
    phrase = item.get("phrase")
    if phrase:
        all_phrases_info[phrase]["usage_variants"] = {
            "oof_prob_class": item.get("oof_prob_class"),
            "is_term_manual": item.get("is_term_manual"),
            "usage_variants": item.get("usage_variants", [])
        }

# === CREATING ANALYTICAL TABLES ===

# 1. Table: Number of synonyms generated by each model for each phrase
rows = []
for phrase, models_data in all_phrases_info.items():
    deep_pavlov_syn_count = len(models_data.get("deep_pavlov", {}).get("synonyms", []))
    rut5_syn_count = len(models_data.get("rut5", {}).get("top_paraphrases", []))
    sbert_syn_count = len(models_data.get("sbert", {}).get("synonyms", []))
    usage_count = len(models_data.get("usage_variants", {}).get("usage_variants", []))

    rows.append({
        "phrase": phrase,
        "deep_pavlov_syn_count": deep_pavlov_syn_count,
        "rut5_syn_count": rut5_syn_count,
        "sbert_syn_count": sbert_syn_count,
        "usage_variants_count": usage_count
    })

df_counts = pd.DataFrame(rows)

# Save as Excel file
df_counts.to_excel("synonym_counts_comparison.xlsx", index=False)

# Compute average synonym count per model
avg_deep = df_counts["deep_pavlov_syn_count"].mean()
avg_rut5 = df_counts["rut5_syn_count"].mean()
avg_sbert = df_counts["sbert_syn_count"].mean()
avg_usage = df_counts["usage_variants_count"].mean()

df_avg = pd.DataFrame({
    "method": ["deep_pavlov", "rut5", "sbert", "usage_variants"],
    "avg_syn_count": [avg_deep, avg_rut5, avg_sbert, avg_usage]
})

# Plot average number of synonyms per method
plt.figure(figsize=(6, 4))
sns.barplot(data=df_avg, x="method", y="avg_syn_count")
plt.title("Average number of synonyms per phrase")
plt.ylabel("Average count")
plt.xlabel("Method")
plt.tight_layout()
plt.savefig("avg_syn_count.png", dpi=150)
plt.close()

# 2. Compare average oof_prob_class across models
oof_rows = []
for phrase, models_data in all_phrases_info.items():
    # DeepPavlov
    dp_val = models_data.get("deep_pavlov", {}).get("oof_prob_class", None)
    if dp_val is not None:
        oof_rows.append({"phrase": phrase, "model": "deep_pavlov", "oof_prob_class": dp_val})
    # RuT5
    rt_val = models_data.get("rut5", {}).get("oof_prob_class", None)
    if rt_val is not None:
        oof_rows.append({"phrase": phrase, "model": "rut5", "oof_prob_class": rt_val})
    # SBERT
    sb_val = models_data.get("sbert", {}).get("oof_prob_class", None)
    if sb_val is not None:
        oof_rows.append({"phrase": phrase, "model": "sbert", "oof_prob_class": sb_val})
    # Usage (опционально, если хотим сравнить одинаково)
    us_val = models_data.get("usage_variants", {}).get("oof_prob_class", None)
    if us_val is not None:
        oof_rows.append({"phrase": phrase, "model": "usage_variants", "oof_prob_class": us_val})

df_oof = pd.DataFrame(oof_rows)

# Boxplot to visualize oof_prob_class distribution across models
plt.figure(figsize=(8, 5))
sns.boxplot(data=df_oof, x="model", y="oof_prob_class")
plt.title("Distribution of oof_prob_class by model")
plt.tight_layout()
plt.savefig("oof_prob_class_boxplot.png", dpi=150)
plt.close()

# 3. Compute synonym overlap between models
overlap_rows = []
for phrase, models_data in all_phrases_info.items():
    dp_syns = set()
    for syn in models_data.get("deep_pavlov", {}).get("synonyms", []):
        dp_syns.add(syn.get("new_phrase") or syn.get("candidate_word", ""))
    rut5_syns = set(models_data.get("rut5", {}).get("top_paraphrases", []))
    sbert_syns = set()
    for syn in models_data.get("sbert", {}).get("synonyms", []):
        sbert_syns.add(syn.get("key", ""))

    intersection_dp_rut5 = dp_syns.intersection(rut5_syns)
    intersection_dp_sbert = dp_syns.intersection(sbert_syns)
    intersection_rut5_sbert = rut5_syns.intersection(sbert_syns)
    intersection_all = dp_syns.intersection(rut5_syns).intersection(sbert_syns)

    overlap_rows.append({
        "phrase": phrase,
        "dp_syn_count": len(dp_syns),
        "rut5_syn_count": len(rut5_syns),
        "sbert_syn_count": len(sbert_syns),
        "dp_rut5_overlap": len(intersection_dp_rut5),
        "dp_sbert_overlap": len(intersection_dp_sbert),
        "rut5_sbert_overlap": len(intersection_rut5_sbert),
        "all_three_overlap": len(intersection_all)
    })

df_overlap = pd.DataFrame(overlap_rows)
df_overlap.to_excel("synonym_overlap.xlsx", index=False)

sum_dp = df_overlap["dp_syn_count"].sum()
sum_rut5 = df_overlap["rut5_syn_count"].sum()
sum_sbert = df_overlap["sbert_syn_count"].sum()
sum_dp_rut5 = df_overlap["dp_rut5_overlap"].sum()
sum_dp_sbert = df_overlap["dp_sbert_overlap"].sum()
sum_rut5_sbert = df_overlap["rut5_sbert_overlap"].sum()
sum_all = df_overlap["all_three_overlap"].sum()

# Print summary statistics
print("Total synonyms DeepPavlov:", sum_dp)
print("Total synonyms RuT5:", sum_rut5)
print("Total synonyms SBERT:", sum_sbert)
print("Total overlap DP-RuT5:", sum_dp_rut5)
print("Total overlap DP-SBERT:", sum_dp_sbert)
print("Total overlap RuT5-SBERT:", sum_rut5_sbert)
print("Total overlap among all three:", sum_all)