# README

Это репозиторий с экспериментальной системой для **автоматического построения тезаурусов** и анализа терминов в рамках узкой предметной области. Проект объединяет несколько этапов лингвистической и семантической обработки текстов, позволяя извлекать устойчивые фразы, фильтровать шумовые элементы, вычислять различные метрики (в том числе на базе **Latent Semantic Analysis**), а затем дополнять результаты информацией о гипонимических отношениях.

---

## Основные возможности

1. **Сбор многословных фраз**
   На основе заранее определённых **грамматических шаблонов** (описанных в файле `patterns-file`), система исследует тексты, выделяет потенциально значимые словосочетания и формирует хранилище фраз (см. команду `collect_phrases`).

2. **Фильтрация корпуса**
   В ходе подготовки текстов происходит удаление «шума»: убираются строки с кодом, формулы, эмодзи, слишком короткие предложения и т. д. Цель — оставить в корпусе лишь более-менее оформленный естественный язык (команда `filter_corpus`).

3. **Анализ частотных метрик**
   На этапе вычисления текстовых метрик (команда `compute_text_metrics`) выполняются операции по слиянию схожих кластеров фраз и вычислению TF-IDF.

4. **Загрузка гиперонимов**
   При необходимости можно обогатить хранилище внешними лексическими ресурсами (WikiWordNet), добавляя связи «гипоним–гипероним» к леммам в составе фраз (команда `load_hypernyms`).

5. **LSA-анализ (Latent Semantic Analysis)**
   Важный блок системы, позволяющий выявлять скрытые семантические темы и рассчитывать метрики, основанные на результатах сингулярного разложения (SVD) (команда `perform_lsa`). В частности:
   - **topic_relevance** — насколько конкретная фраза/кластер терминов релевантны выделенным темам,
   - **centrality_score** — мера «центральности» (или «типичности») фразы внутри своего тематического кластера.

6. **Выделение терминологических фраз**
   Финальный шаг отбора действительно значимых терминов; фильтрация и сохранение списка кандидатов (команда `get_terminological_phrases`).

---

## Зависимости
- Библиотеки:
  - [XMorphy](https://github.com/alesapin/XMorphy) для проведения морфологического анализа,
  - [Boost](https://www.boost.org/),
  - [Eigen3](https://eigen.tuxfamily.org/) для линейной алгебры и проведения SVD,
  - ICU (International Components for Unicode) для очистки текстов.

---

## Запуск и использование
Программа работает в консольном режиме. Основная форма вызова:
```bash
./AutoThematicThesaurus <command> [options]
```